{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "#from statsmodels.tsa.holtwinters  import SimpleExpSmoothing, Holt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_butter=pd.read_csv('dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.543521</td>\n",
       "      <td>0.536693</td>\n",
       "      <td>0.529900</td>\n",
       "      <td>0.523143</td>\n",
       "      <td>0.516427</td>\n",
       "      <td>0.509753</td>\n",
       "      <td>0.503124</td>\n",
       "      <td>0.496543</td>\n",
       "      <td>0.490013</td>\n",
       "      <td>0.483537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367887</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "      <td>0.367886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.458166</td>\n",
       "      <td>0.456752</td>\n",
       "      <td>0.455336</td>\n",
       "      <td>0.453918</td>\n",
       "      <td>0.452499</td>\n",
       "      <td>0.451079</td>\n",
       "      <td>0.449659</td>\n",
       "      <td>0.448240</td>\n",
       "      <td>0.446821</td>\n",
       "      <td>0.445404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392877</td>\n",
       "      <td>0.392877</td>\n",
       "      <td>0.392878</td>\n",
       "      <td>0.392878</td>\n",
       "      <td>0.392878</td>\n",
       "      <td>0.392879</td>\n",
       "      <td>0.392879</td>\n",
       "      <td>0.392879</td>\n",
       "      <td>0.392879</td>\n",
       "      <td>0.392879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938540</td>\n",
       "      <td>0.948536</td>\n",
       "      <td>0.958461</td>\n",
       "      <td>0.968311</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.987773</td>\n",
       "      <td>0.997377</td>\n",
       "      <td>1.006894</td>\n",
       "      <td>1.016319</td>\n",
       "      <td>1.025650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>0.554425</td>\n",
       "      <td>0.554425</td>\n",
       "      <td>0.554425</td>\n",
       "      <td>0.554425</td>\n",
       "      <td>0.554425</td>\n",
       "      <td>0.554426</td>\n",
       "      <td>0.554426</td>\n",
       "      <td>0.554426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117722</td>\n",
       "      <td>0.118147</td>\n",
       "      <td>0.118589</td>\n",
       "      <td>0.119049</td>\n",
       "      <td>0.119526</td>\n",
       "      <td>0.120020</td>\n",
       "      <td>0.120531</td>\n",
       "      <td>0.121058</td>\n",
       "      <td>0.121603</td>\n",
       "      <td>0.122163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573146</td>\n",
       "      <td>0.573142</td>\n",
       "      <td>0.573138</td>\n",
       "      <td>0.573135</td>\n",
       "      <td>0.573132</td>\n",
       "      <td>0.573130</td>\n",
       "      <td>0.573128</td>\n",
       "      <td>0.573126</td>\n",
       "      <td>0.573125</td>\n",
       "      <td>0.573124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.442304</td>\n",
       "      <td>0.437091</td>\n",
       "      <td>0.431882</td>\n",
       "      <td>0.426682</td>\n",
       "      <td>0.421490</td>\n",
       "      <td>0.416311</td>\n",
       "      <td>0.411145</td>\n",
       "      <td>0.405996</td>\n",
       "      <td>0.400865</td>\n",
       "      <td>0.395756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.358347</td>\n",
       "      <td>0.358347</td>\n",
       "      <td>0.358346</td>\n",
       "      <td>0.358346</td>\n",
       "      <td>0.358346</td>\n",
       "      <td>0.358346</td>\n",
       "      <td>0.358345</td>\n",
       "      <td>0.358345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.543521  0.536693  0.529900  0.523143  0.516427  0.509753  0.503124   \n",
       "1  0.458166  0.456752  0.455336  0.453918  0.452499  0.451079  0.449659   \n",
       "2  0.938540  0.948536  0.958461  0.968311  0.978083  0.987773  0.997377   \n",
       "3  0.117722  0.118147  0.118589  0.119049  0.119526  0.120020  0.120531   \n",
       "4  0.442304  0.437091  0.431882  0.426682  0.421490  0.416311  0.411145   \n",
       "\n",
       "          7         8         9  ...      5990      5991      5992      5993  \\\n",
       "0  0.496543  0.490013  0.483537  ...  0.367887  0.367886  0.367886  0.367886   \n",
       "1  0.448240  0.446821  0.445404  ...  0.392877  0.392877  0.392878  0.392878   \n",
       "2  1.006894  1.016319  1.025650  ...  0.554424  0.554424  0.554425  0.554425   \n",
       "3  0.121058  0.121603  0.122163  ...  0.573146  0.573142  0.573138  0.573135   \n",
       "4  0.405996  0.400865  0.395756  ...  0.358348  0.358348  0.358347  0.358347   \n",
       "\n",
       "       5994      5995      5996      5997      5998      5999  \n",
       "0  0.367886  0.367886  0.367886  0.367886  0.367886  0.367886  \n",
       "1  0.392878  0.392879  0.392879  0.392879  0.392879  0.392879  \n",
       "2  0.554425  0.554425  0.554425  0.554426  0.554426  0.554426  \n",
       "3  0.573132  0.573130  0.573128  0.573126  0.573125  0.573124  \n",
       "4  0.358346  0.358346  0.358346  0.358346  0.358345  0.358345  \n",
       "\n",
       "[5 rows x 6000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_butter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import *\n",
    "frame=6000\n",
    "step=1\n",
    "signal=df_butter.to_numpy()\n",
    "\n",
    "\n",
    "variance = []\n",
    "rms = []\n",
    "iemg = []\n",
    "mav = []\n",
    "log_detector = []\n",
    "wl = []\n",
    "aac = []\n",
    "dasdv = []\n",
    "zc = []\n",
    "wamp = []\n",
    "myop = []\n",
    "\n",
    "th = np.mean(signal[0]) + 3 * np.std(signal[0])\n",
    "\n",
    "\n",
    "x = signal[0]\n",
    "\n",
    "#variance.append(np.var(x))\n",
    "rms.append(np.sqrt(np.mean(x ** 2)))\n",
    "iemg.append(np.sum(abs(x)))  # Integral\n",
    "mav.append(np.sum(np.absolute(x)) )  # Mean Absolute Value\n",
    "wl.append(np.sum(abs(np.diff(x))))  # Wavelength\n",
    "aac.append(np.sum(abs(np.diff(x))) )  # Average Amplitude Change\n",
    "dasdv.append(\n",
    "    math.sqrt( np.sum((np.diff(x)) ** 2)))  # Difference absolute standard deviation value\n",
    "#zc.append(zcruce(x, th))  # Zero-Crossing\n",
    "wamp.append(wilson_amplitude(x, th))  # Willison amplitude\n",
    "myop.append(myopulse(x, th))  # Myopulse percentage rate\n",
    "\n",
    "x_input= np.column_stack(( rms, iemg, mav, wl, aac, dasdv, wamp, myop))\n",
    "for i in range(len(signal)-1):\n",
    "    \n",
    "\n",
    "    variance = []\n",
    "    rms = []\n",
    "    iemg = []\n",
    "    mav = []\n",
    "    log_detector = []\n",
    "    wl = []\n",
    "    aac = []\n",
    "    dasdv = []\n",
    "    zc = []\n",
    "    wamp = []\n",
    "    myop = []\n",
    "\n",
    "    th = np.mean(signal[i]) + 3 * np.std(signal[i])\n",
    "\n",
    "\n",
    "    x = signal[i]\n",
    "\n",
    "    #variance.append(np.var(x))\n",
    "    rms.append(np.sqrt(np.mean(x ** 2)))\n",
    "    iemg.append(np.sum(abs(x)))  # Integral\n",
    "    mav.append(np.sum(np.absolute(x)) )  # Mean Absolute Value\n",
    "    wl.append(np.sum(abs(np.diff(x))))  # Wavelength\n",
    "    aac.append(np.sum(abs(np.diff(x))) )  # Average Amplitude Change\n",
    "    dasdv.append(\n",
    "        math.sqrt( np.sum((np.diff(x)) ** 2)))  # Difference absolute standard deviation value\n",
    "    #zc.append(zcruce(x, th))  # Zero-Crossing\n",
    "    wamp.append(wilson_amplitude(x, th))  # Willison amplitude\n",
    "    myop.append(myopulse(x, th))  # Myopulse percentage rate\n",
    "\n",
    "    tt= np.column_stack(( rms, iemg, mav, wl, aac, dasdv, wamp, myop))\n",
    "    x_input=np.row_stack((x_input,tt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('data.csv')\n",
    "df_labels = dataset.iloc[:, 6001]\n",
    "label_dict = {\n",
    "    'Spherical':1,\n",
    "    'Tip':2,\n",
    "    'Palmar':3,\n",
    "    'Lateral':4,\n",
    "    'Cylindrical':5,\n",
    "    'Hook':6}\n",
    "\n",
    "col = [label_dict[i] for i in df_labels.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Transform\n",
    "n = 8\n",
    "pca = PCA(n_components=n).fit(df_butter.T)\n",
    "df_pca = pca.components_.T\n",
    "\n",
    "#Isomap Transform\n",
    "iso = Isomap(n_components=n)\n",
    "df_iso = iso.fit_transform(df_butter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "Six classification models were used to classify the data. We found no difference in the PCA and Isomap dataframe accuracies, so for all of the models we used \"df_iso\" as our final dataset. Here are the classification models used.\n",
    "\n",
    "* Support Vector Machine \n",
    "* Logistic Regression\n",
    "* Neural Net\n",
    "* K-Means\n",
    "* Gaussian Mixture\n",
    "* Naive-Bayes\n",
    "\n",
    "All hyper-parameters were tuned through grid search. The following models show the optimal hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_res = []\n",
    "log_res = []\n",
    "nn_res = []\n",
    "nb_res = []\n",
    "kmeans_res = []\n",
    "gmm_res = []\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_input, \n",
    "                                                        df_labels, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=i)\n",
    "\n",
    "    clf_svc = make_pipeline(StandardScaler(), SVC(gamma='auto', C=10))\n",
    "    clf_log = make_pipeline(StandardScaler(), LogisticRegression(C=10, max_iter=1000))\n",
    "    clf_nn = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(200,200,200), max_iter=2000))\n",
    "    clf_nb = make_pipeline(StandardScaler(), GaussianNB())\n",
    "    clf_kmeans = make_pipeline(StandardScaler(), KMeans(n_clusters=6))\n",
    "    clf_gmm = make_pipeline(StandardScaler(), GMM(n_components=6))\n",
    "    \n",
    "    clfs = [clf_svc, \n",
    "            clf_log, \n",
    "            clf_nn, \n",
    "            clf_nb, \n",
    "            clf_kmeans, \n",
    "            clf_gmm]\n",
    "    \n",
    "    for c in clfs:\n",
    "        c.fit(X_train, y_train)\n",
    "\n",
    "    svm_labels = clf_svc.predict(X_test)\n",
    "    log_labels = clf_log.predict(X_test)\n",
    "    nn_labels = clf_nn.predict(X_test)\n",
    "    nb_labels = clf_nb.predict(X_test)\n",
    "    kmeans_labels = clf_kmeans.predict(X_test)\n",
    "    gmm_labels = clf_gmm.predict(X_test)\n",
    "\n",
    "    svm_res.append(((svm_labels == y_test).value_counts()/len(X_test))[1])\n",
    "    log_res.append(((log_labels == y_test).value_counts()/len(X_test))[1])\n",
    "    nn_res.append(((nn_labels == y_test).value_counts()/len(X_test))[1])\n",
    "    nb_res.append(((nb_labels == y_test).value_counts()/len(X_test))[1])\n",
    "    kmeans_res.append(1 - (sum([abs(i[0] - i[1]) for i in zip(sorted(np.bincount(le.transform(y_test))), \n",
    "                                       sorted(np.bincount(kmeans_labels)))])/len(y_test)))\n",
    "    gmm_res.append(1 - (sum([abs(i[0] - i[1]) for i in zip(sorted(np.bincount(le.transform(y_test))), \n",
    "                                       sorted(np.bincount(gmm_labels)))])/len(y_test)))\n",
    "\n",
    "svm_score = np.max(np.max(np.array(svm_res)))\n",
    "log_score = np.max(np.max(np.array(log_res)))\n",
    "nn_score = np.max(np.max(np.array(nn_res)))\n",
    "nb_score = np.max(np.max(np.array(nb_res)))\n",
    "kmeans_score = np.max(np.max(np.array(kmeans_res)))\n",
    "gmm_score = np.max(np.max(np.array(gmm_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy:  0.5555555555555556\n",
      "LR Accuracy:  0.49444444444444446\n",
      "Neural Network accuracy: 0.6555555555555556\n",
      "Naive Bayes accuracy 0.4666666666666667\n",
      "K-Means accuracy: 0.6555555555555556\n",
      "GMM accuracy 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy: \", svm_score)\n",
    "print(\"LR Accuracy: \", log_score)\n",
    "print(\"Neural Network accuracy:\", nn_score)\n",
    "print(\"Naive Bayes accuracy\", nb_score)\n",
    "print(\"K-Means accuracy:\", kmeans_score)\n",
    "print(\"GMM accuracy\", gmm_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b7d1ef90942d86d25c66ba21e7443fa34dad65b15a43678a36cbf2cd904866b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
